{"0": {
    "doc": "Staff Pictures",
    "title": "Staff Pictures",
    "content": "Staff pictures go here . ",
    "url": "/fa23/resources/assets/staff_pics/README/",
    
    "relUrl": "/resources/assets/staff_pics/README/"
  },"1": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": "Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"2": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": "All course events are listed in the following calendar. Click on the events to check the locations. ",
    "url": "/fa23/calendar/",
    
    "relUrl": "/calendar/"
  },"3": {
    "doc": "Home / Schedule",
    "title": "Data 102: Data, Inference, and Decisions",
    "content": "UC Berkeley, Fall 2023 . Aditya Guntuboyina . aditya@stat.berkeley.edu . Ramesh Sridharan . ramesh_s@berkeley.edu . This website is still a work in progress. All contents on this page are subject to change until this message is taken down. ",
    "url": "/fa23/#data-102-data-inference-and-decisions",
    
    "relUrl": "/#data-102-data-inference-and-decisions"
  },"4": {
    "doc": "Home / Schedule",
    "title": "Schedule",
    "content": " ",
    "url": "/fa23/#schedule",
    
    "relUrl": "/#schedule"
  },"5": {
    "doc": "Home / Schedule",
    "title": "Week 1: Introductions",
    "content": "Aug 24 Lecture 1 Course Overview Vitamin Vitamin 1 (due Aug 28) ",
    "url": "/fa23/#week-1-introductions",
    
    "relUrl": "/#week-1-introductions"
  },"6": {
    "doc": "Home / Schedule",
    "title": "Week 2: Decisions I",
    "content": "Aug 28 Lab 0 Review and Warm-up (due Aug 30) Aug 29 Lecture 2 Binary Decision-Making Aug 30 Discussion Discussion 1 Aug 31 Lecture 3 P-Values and Multiple Hypothesis Testing Vitamin Vitamin 2 (due Sep 3) Sep 1 Homework Homework 1 (due Sep 15) ",
    "url": "/fa23/#week-2-decisions-i",
    
    "relUrl": "/#week-2-decisions-i"
  },"7": {
    "doc": "Home / Schedule",
    "title": "Week 3: Decisions II",
    "content": "Sep 4 Lab 1 Basics of Testing (due Sep 6) Sep 5 Lecture 4 Online False Discovery Rate Control &amp; ROC curves Sep 6 Discussion Discussion 2 Sep 7 Lecture 5 Frequentist vs. Bayesian Decision-Making Vitamin Vitamin 3 (due Sep 10) ",
    "url": "/fa23/#week-3-decisions-ii",
    
    "relUrl": "/#week-3-decisions-ii"
  },"8": {
    "doc": "Home / Schedule",
    "title": "Week 4: Bayesian Modeling I",
    "content": "Sep 11 Lab 2 Loss and Risk (due Sep 13) Sep 12 Lecture 6 Overview of Bayesian Modeling Sep 13 Discussion Discussion 3 Sep 14 Lecture 7 Graphical Models Vitamin Vitamin 4 (due Sep 17) Sep 15 Homework Homework 2 (due Sep 29) ",
    "url": "/fa23/#week-4-bayesian-modeling-i",
    
    "relUrl": "/#week-4-bayesian-modeling-i"
  },"9": {
    "doc": "Home / Schedule",
    "title": "Week 5: Bayesian Modeling II",
    "content": "Sep 18 Lab 3 Bayesian Estimation in Hierarchical Graphical Models (due Sep 20) Sep 19 Lecture 8 Rejection Sampling and Markov Chains Sep 20 Discussion Discussion 4 Sep 21 Lecture 9 Markov Chain Monte Carlo (MCMC) and Gibbs Sampling Vitamin Vitamin 5 (due Sep 24) ",
    "url": "/fa23/#week-5-bayesian-modeling-ii",
    
    "relUrl": "/#week-5-bayesian-modeling-ii"
  },"10": {
    "doc": "Home / Schedule",
    "title": "Week 6: GLM I",
    "content": "Sep 25 Lab 4 Sampling from Unknown Distributions (due Sep 27) Sep 26 Lecture 10 Regression and GLMs Sep 27 Discussion Discussion 5 Sep 28 Lecture 11 Model checking for GLMs Vitamin Vitamin 6 (due Oct 1) ",
    "url": "/fa23/#week-6-glm-i",
    
    "relUrl": "/#week-6-glm-i"
  },"11": {
    "doc": "Home / Schedule",
    "title": "Week 7: GLM II",
    "content": "Oct 2 Lab 5 GLM and the Bootstrap (due Oct 4) Oct 3 Lecture 12 Uncertainty quantification for GLMs Oct 4 Discussion Discussion 6 Oct 5 Midterm Midterm 1 Vitamin Vitamin 7 (due Oct 8) Oct 6 Homework Homework 3 (due Oct 20) ",
    "url": "/fa23/#week-7-glm-ii",
    
    "relUrl": "/#week-7-glm-ii"
  },"12": {
    "doc": "Home / Schedule",
    "title": "Week 8: Machine Learning",
    "content": "Oct 10 Lecture 13 Nonparametric Methods and Neural Networks Oct 11 Discussion Discussion 7 Oct 12 Lecture 14 Neural Networks and Interpretability Vitamin Vitamin 8 (due Oct 15) ",
    "url": "/fa23/#week-8-machine-learning",
    
    "relUrl": "/#week-8-machine-learning"
  },"13": {
    "doc": "Home / Schedule",
    "title": "Week 9: Causal Inference I",
    "content": "Oct 16 Lab 6 Nonparametric Methods (due Oct 18) Oct 17 Lecture 15 Association and Causation Oct 18 Discussion Discussion 8 Oct 19 Lecture 16 Randomized Experiments Vitamin Vitamin 9 (due Oct 22) Oct 20 Homework Homework 4 (due Nov 3) ",
    "url": "/fa23/#week-9-causal-inference-i",
    
    "relUrl": "/#week-9-causal-inference-i"
  },"14": {
    "doc": "Home / Schedule",
    "title": "Week 10: Causal Inference II",
    "content": "Oct 23 Lab 7 Causal Inference via Instrumental Variables (due Oct 25) Oct 24 Lecture 17 Observational Studies Oct 25 Discussion Discussion 9 Oct 26 Lecture 18 Concentration Inequalities Vitamin Vitamin 10 (due Oct 29) ",
    "url": "/fa23/#week-10-causal-inference-ii",
    
    "relUrl": "/#week-10-causal-inference-ii"
  },"15": {
    "doc": "Home / Schedule",
    "title": "Week 11: Bandits",
    "content": "Oct 30 Lab 8 Causal Inference via Unconfoundedness (due Nov 1) Oct 31 Lecture 19 Bandits I Nov 1 Discussion Discussion 10 Nov 2 Lecture 20 Bandits II Vitamin Vitamin 11 (due Nov 5) Nov 3 Homework Homework 5 (due Nov 10) ",
    "url": "/fa23/#week-11-bandits",
    
    "relUrl": "/#week-11-bandits"
  },"16": {
    "doc": "Home / Schedule",
    "title": "Week 12: Reinforcement Learning",
    "content": "Nov 6 Lab 9 Bandits (due Nov 8) Nov 7 Lecture 21 Reinforcement Learning I Nov 8 Discussion Discussion 11 Nov 9 Lecture 22 Reinforcement Learning II Vitamin Vitamin 12 (due Nov 12) ",
    "url": "/fa23/#week-12-reinforcement-learning",
    
    "relUrl": "/#week-12-reinforcement-learning"
  },"17": {
    "doc": "Home / Schedule",
    "title": "Week 13: Regression revisited",
    "content": "Nov 13 Lab 10 Reinforcement Learning (due Nov 15) Nov 14 Midterm Midterm 2 Nov 16 Lecture 23 High-dimensional regression Vitamin Vitamin 13 (due Nov 19) Nov 17 Homework Homework 6 (due Dec 1) ",
    "url": "/fa23/#week-13-regression-revisited",
    
    "relUrl": "/#week-13-regression-revisited"
  },"18": {
    "doc": "Home / Schedule",
    "title": "Week 14: Privacy",
    "content": "Nov 21 Lecture 24 Differential Privacy Nov 23 Thanksgiving ",
    "url": "/fa23/#week-14-privacy",
    
    "relUrl": "/#week-14-privacy"
  },"19": {
    "doc": "Home / Schedule",
    "title": "Week 15: Wrap-Up",
    "content": "Nov 27 Lab 11 Differential Privacy (due Nov 29) Nov 28 Lecture 25 Case Study: Robustness and generalization Nov 29 Discussion Discussion 12 Nov 30 Lecture 26 Course Wrap-Up ",
    "url": "/fa23/#week-15-wrap-up",
    
    "relUrl": "/#week-15-wrap-up"
  },"20": {
    "doc": "Home / Schedule",
    "title": "Home / Schedule",
    "content": " ",
    "url": "/fa23/",
    
    "relUrl": "/"
  },"21": {
    "doc": "Lecture 1 – Course Overview",
    "title": "Lecture 1 – Introduction",
    "content": "Presented by Bella Crouch and Dominic Liu . Content by many dedicated Data 100 instructors at UC Berkeley. See our Acknowledgments page. | slides | code | code HTML | recording | . ",
    "url": "/fa23/lecture/lec01/#lecture-1--introduction",
    
    "relUrl": "/lecture/lec01/#lecture-1--introduction"
  },"22": {
    "doc": "Lecture 1 – Course Overview",
    "title": "Lecture 1 – Course Overview",
    "content": " ",
    "url": "/fa23/lecture/lec01/",
    
    "relUrl": "/lecture/lec01/"
  },"23": {
    "doc": "Resources",
    "title": "Resources",
    "content": "Here is a collection of resources that will help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these and other materials. If you find something helpful, post it on EdStem, and consider contributing it to the course website. Jump to: . | Exam Resources | Web References | Textbooks from Previous Data Science Courses | Reading Resources | . ",
    "url": "/fa23/resources/",
    
    "relUrl": "/resources/"
  },"24": {
    "doc": "Resources",
    "title": "Exam Resources",
    "content": "| Semester | Midterm (1) | Midterm 2 | Final | . | Spring 2023 | Exam (Solutions) | Exam (Solutions) |   | . | Fall 2022 | Exam (Solutions) | Exam (Solutions) |   | . | Spring 2022 | Exam (Solutions) | Exam (Solutions) |   | . | Fall 2021 | Exam (Solutions) | Exam (Solutions) |   | . | Spring 2021 | Exam (Solutions) | Exam (Solutions) |   | . | Fall 2020 | Exam (Solutions) |   | Exam (Solutions) | . | Spring 2020 | Exam (Solutions) |   |   | . | Fall 2019 | Exam (Solutions) |   | Exam (Solutions) | . Here is a collection of resources that may help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well-rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these materials. ",
    "url": "/fa23/resources/#exam-resources",
    
    "relUrl": "/resources/#exam-resources"
  },"25": {
    "doc": "Resources",
    "title": "Web References",
    "content": "In this class we will be using several key libraries. Here are their documentation pages: . | Python: . | Python Tutorial: Teach yourself python. This is a pretty comprehensive tutorial. | Python + Numpy Tutorial this tutorial provides a great overview of a lot of the functionality we will be using in DS102. | Python 101: A notebook demonstrating a lot of python functionality with some (minimal explanation). | . | Plotting: . | matplotlib.pyplot tutorial: This short tutorial provides an overview of the basic plotting utilities we will be using. | seaborn: The Seaborn library has some nice additional visualization functions that we may use occasionally. | . | Pandas: . | The Pandas Cookbook: This provides a nice overview of some of the basic Pandas functions. However, it is slightly out of date. | Learn Pandas A set of lessons providing an overview of the Pandas library. | Python for Data Science Another set of notebook demonstrating Pandas functionality. | Python for Data Analysis (Available as eBook for Berkeley students). This book provides a good reference for the Pandas library. | . | . ",
    "url": "/fa23/resources/#web-references",
    
    "relUrl": "/resources/#web-references"
  },"26": {
    "doc": "Resources",
    "title": "Textbooks from Previous Data Science Courses",
    "content": "Data 102 builds on material taught in previous data science courses. You may find the textbooks from those courses helpful: . | Data 8 | Data 100 | Data 140: even if you took one of the other probability prerequisite courses, this book can be a helpful reference. | . ",
    "url": "/fa23/resources/#textbooks-from-previous-data-science-courses",
    
    "relUrl": "/resources/#textbooks-from-previous-data-science-courses"
  },"27": {
    "doc": "Resources",
    "title": "Reading Resources",
    "content": ". | Data 102 Textbook Because data science is a relatively new and rapidly evolving discipline there is no single ideal textbook for this subject. The instructors are in the process of developing this online textbook for the course, they will be updating the textbook as semester progresses. You can also find useful reading among the following collection of books, all of which are free . | Patterns, Predictions, and Actions This book is a great introduction to many of the topics we cover in this course, as well as several other important topics in advanced machine learning and data science. The following chapters are particularly relevant to this class: . | Chapter 2 covers decision theory. | Chapter 8 covers datasets: even though we won’t be talking about this much in Data 102, this is an extremely important topic to know about for doing real-world data science. | Chapters 9 and 10 cover causal inference. | Chapter 12 covers reinforcement learning. | . | Statistical Rethinking This popular online graduate course is an excellent introduction to thinking about statistics through a Bayesian and causal lens. While it goes into much more detail than Data 102 does, lectures 2, 5, and 8 are all closely related to what we cover. | All of Statistics This book is a great, broad introduction to mathematical statistics. It begins with probability concepts (e.g. Bayes’ theorem), works through many statistical inference topics (e.g. hypothesis testing, decision theory, and bootstrap, and also includes statistical modeling (e.g. regression and causal inference)). The textbook as a whole covers many more ideas from statistics than will be used in or needed for this course, but students may still find it useful to reference specific topics within it to supplement ideas covered in lecture or review ideas from previous courses. For example: . | Chapters 1-3 review some background ideas about probability and random variables | Chapter 12 discusses the statistical decision theory framework | Section 9.3 reviews maximum likelihood estimation, while the first few sections of chapter 11 review the core idea behind Bayesian inference | Sections 10.2, 10.6, and 10.7 cover p-values, the likelihood ratio test, and multiple testing ideas | Chapter 13 covers linear and logistic regression | Chapters 7-8 review empirical distributions and bootstrap | Chapter 16 covers causal inference | . | Computer-Age Statistical Inference This book takes a fairly modern view of statistics, often examining the influence of computation on the field. It is useful to keep in mind that the book was written with masters’ students in mind. As such, this textbook covers many topics beyond the scope of this course, but nevertheless provides useful, high-level discussion of some course topics for those students looking for additional information. For example: . | Chapters 2 and 3 do an excellent job of comparing and contrasting frequentist and Bayesian inference, with illustrative examples | Chapter 4 discusses maximum likelihood estimation | Chapter 15 provides additional details about multiple hypothesis testing and false discovery rate control | There is also one section each on logistic regression, the EM algorithm, the bootstrap, conjugate priors, and Gibbs sampling | . | Causal Inference: The Mixtape This book is a great introduction and reference for all things causal inference. | Introduction to Statistical Learning (Free online PDF) This book is a great reference for the machine learning and some of the statistics material in the class . | Data Science from Scratch (Available as eBook for Berkeley students) This more applied book covers many of the topics in this class using Python but doesn’t go into sufficient depth for some of the more mathematical material. | Doing Data Science (Available as eBook for Berkeley students) This books provides a unique case-study view of data science but uses R and not Python. | Matrix Cookbook This “cookbook” is a handy collection of facts about linear algebra and matrices. | . ",
    "url": "/fa23/resources/#reading-resources",
    
    "relUrl": "/resources/#reading-resources"
  },"28": {
    "doc": "Local Setup",
    "title": "Local Setup",
    "content": "We will still be using datahub as our primary computing environment. This page serves as a guide for alternative environment setup. In other words: you don’t have to follow these instructions unless you’d like an alternative to datahub. ",
    "url": "/fa23/setup/",
    
    "relUrl": "/setup/"
  },"29": {
    "doc": "Local Setup",
    "title": "Contents",
    "content": ". | Installing conda by OS . | OSX | Windows | Linux | . | Creating your environment | Working on assignments locally | Opening notebooks locally | Verifying your environment | Removing the environment to start over | Submitting your work | FAQ | . ",
    "url": "/fa23/setup/#contents",
    
    "relUrl": "/setup/#contents"
  },"30": {
    "doc": "Local Setup",
    "title": "OSX",
    "content": ". | You will need access to the command line. On a Mac, you can open the Terminal by opening Spotlight (Cmd + Space) and typing \"Terminal\". Alternatively, you can go to your Applications screen and select Terminal (it might be in the folder named \"Other\") . | Homebrew is a package manager for OSX. If you haven’t already, install it by running the following in the command line (copy, paste, and enter): . # This downloads the Ruby code of the installation script and runs it /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" . Verify your installation by making sure brew --version doesn’t error at your terminal. | Download and install Anaconda: . # Uses curl to download the installation script curl https://repo.continuum.io/miniconda/Miniconda2-4.5.11-MacOSX-x86_64.sh &gt; miniconda.sh # Run the miniconda installer (you will need to enter your password) bash miniconda.sh . | Close and restart your terminal. Ensure the installation worked by running conda --version. | . You may remove the miniconda.sh script now if you’d like. Click here to continue to the next part of the setup. ",
    "url": "/fa23/setup/#osx",
    
    "relUrl": "/setup/#osx"
  },"31": {
    "doc": "Local Setup",
    "title": "Windows",
    "content": "Windows is especially prone to error if you aren’t careful about your configuration. If you’ve already had Anaconda or git installed and can’t get the other to work, try uninstalling everything and starting from scratch. Installing Anaconda: . | Visit the Anaconda website and download the installer for Python 3.7. Download the 64-bit installer if your computer is 64-bit (most likely), the 32-bit installer if not. See this FAQ if you are unsure. | Run the exe file to install Anaconda. Leave all the options as default (install for all users, in the default location). Make sure both of these checkboxes are checked: . | . 1) Verify that the installation is working by starting the Anaconda Prompt (you should be able to start it from the Start Menu) and typing python: . Notice how the python prompt shows that it is running from Anaconda. Now you have conda installed! . From now on, when we talk about the “Terminal” or “Command Prompt”, we are referring to the Anaconda Prompt that you just installed. Click here to continue to the next part of the setup. ",
    "url": "/fa23/setup/#windows",
    
    "relUrl": "/setup/#windows"
  },"32": {
    "doc": "Local Setup",
    "title": "Linux",
    "content": "These instructions assume you have apt-get (Ubuntu and Debian). For other distributions of Linux, substitute the appropriate package manager. | Your terminal program allows you to type commands to control your computer. On Linux, you can open the Terminal by going to the Applications menu and clicking “Terminal”. | Install wget. This is a command-line tool that lets you download files / webpages at the command line. sudo apt-get install wget . | Download the Anaconda installation script: . wget -O install_anaconda.sh https://repo.continuum.io/miniconda/Miniconda2-4.5.11-Linux-x86_64.sh . | . 4) Install Anaconda: . bash install_anaconda.sh . 5) Close and restart your terminal. Ensure the installation worked by running `conda --version`. You may remove the install_anaconda.sh script now if you’d like. Click here to continue to the next part of the setup. ",
    "url": "/fa23/setup/#linux",
    
    "relUrl": "/setup/#linux"
  },"33": {
    "doc": "Local Setup",
    "title": "Creating your environment",
    "content": "These instructions are the same for OSX, Windows, and Linux. | Download the data100 data100_environment.yml] from the course repository here or: . # download via curl curl https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml &gt; data100_environment.yml # OR download via wget wget -O data100_environment.yml https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml . | . This YAML file is what we use to specify the dependencies and packages (and their versions) we wish to install into the conda environment we will make for this class. The purpose of the environment is to ensure that everyone in the course is using the same package versions for every assignment whether or not they are working on datahub. This is to prevent inconsistent behavior due to differences in package versions. | Using the Terminal, navigate to the directory where you downloaded data100_environment.yml. Run these commands to create a new conda environment. Each conda environment maintains its own package versions, allowing us to switch between package versions easily. For example, this class uses Python 3, but you might have another that uses Python 2. With a conda environment, you can switch between those at will. # sanity check on conda installation. Should be 4.5 or higher conda --version # update conda just in case it's out of date # enter y if prompted to proceed conda update conda # download git conda install -c anaconda git # Create a python 3.6 conda environment with the full set # of packages specified in environment.yml (jupyter, numpy, pandas, ...) conda env create -f data100_environment.yml # Switch to the data100 environment conda activate data100 # Check if packages are in the environment # This should not be empty! conda list . | . From now on, you can switch to the data100 env with conda activate data100, and switch back to the default env with conda deactivate. ",
    "url": "/fa23/setup/#creating-your-environment",
    
    "relUrl": "/setup/#creating-your-environment"
  },"34": {
    "doc": "Local Setup",
    "title": "Working on assignments locally",
    "content": "These instructions are the same for OSX, Windows, and Linux. To work on assignments, you should fetch the assignment on datahub, navigate to the assignment folder and click on the download icon on the top right: . Then you can unzip the files into a folder of your choosing. Remember the location of your assignment files because you’ll need to navigate to that folder to open the notebook. ",
    "url": "/fa23/setup/#working-on-assignments-locally",
    
    "relUrl": "/setup/#working-on-assignments-locally"
  },"35": {
    "doc": "Local Setup",
    "title": "Opening notebooks locally",
    "content": "To open Jupyter notebooks, you’ll navigate to parent directory of the assignment in your terminal, activate the environment, and start up a jupyter server. This will look something like: . cd path/to/assignment/directory conda activate data100 jupyter notebook . This will automatically open the notebook interface in your browser. You can then browse to a notebook and open it. Make sure to always work in the data100 conda environment when you are using jupyter notebooks for this class. This ensures you have all the necessary packages required for the notebook to run. ",
    "url": "/fa23/setup/#opening-notebooks-locally",
    
    "relUrl": "/setup/#opening-notebooks-locally"
  },"36": {
    "doc": "Local Setup",
    "title": "Verifying Your Environment",
    "content": "You can tell if you are correct environment if your terminal looks something like: . Additionally, . conda env list . outputs a list of all your conda environments, and data100 should appear with a * next to it (the active one). ",
    "url": "/fa23/setup/#verifying-your-environment",
    
    "relUrl": "/setup/#verifying-your-environment"
  },"37": {
    "doc": "Local Setup",
    "title": "Removing the environment to start over",
    "content": "If you feel as if you’ve messed up and need to start over, you can remove the environment with . conda remove --name data100 --all . To verify that the environment was removed, in your Terminal window or an Anaconda Prompt, run: . conda info --envs . Which should then no longer display the data100 environment. ",
    "url": "/fa23/setup/#removing-the-environment-to-start-over",
    
    "relUrl": "/setup/#removing-the-environment-to-start-over"
  },"38": {
    "doc": "Local Setup",
    "title": "Submitting your work",
    "content": "Submissions will still be handled via datahub. To upload your work, navigate to the appropriate assignment folder on datahub and click on the upload button on the top right. Remember to validate, submit, and upload to Gradescope (for homeworks and projects). ",
    "url": "/fa23/setup/#submitting-your-work",
    
    "relUrl": "/setup/#submitting-your-work"
  },"39": {
    "doc": "Local Setup",
    "title": "FAQ",
    "content": "Shell not properly configured to use conda activate . If you had an older version of Anaconda installed (perhaps for another class), you may see the following message. Follow the instructions in the prompt to: . | Enable conda for all users sudo ln -s ... | Put the base environment on PATH echo \"conda activate\" &gt;&gt; ~/.bash_profile\". Note that ~/.bash_profile may be something different like ~/.bashrc. | Manually remove the line that looks like export PATH=\"/usr/local/miniconda3/bin:$PATH\" from your .bash_profile. Use your favorite plaintext editor to do this (do not use a rich text editor like Microsoft Word!). | . ",
    "url": "/fa23/setup/#faq",
    
    "relUrl": "/setup/#faq"
  },"40": {
    "doc": "Staff",
    "title": "Staff",
    "content": "Jump to: Instructors, Teaching Assistants, UCS1s. Note: Consult the calendar for the most up-to-date office hours for each GSI. ",
    "url": "/fa23/staff/",
    
    "relUrl": "/staff/"
  },"41": {
    "doc": "Staff",
    "title": "Course Staff Email",
    "content": "Contact course staff via Ed with any questions or concerns. For sensitive matters, the staff email address data102@berkeley.edu is monitored by the instructors and a few lead TAs. ",
    "url": "/fa23/staff/#course-staff-email",
    
    "relUrl": "/staff/#course-staff-email"
  },"42": {
    "doc": "Staff",
    "title": "Instructors",
    "content": "Aditya Guntuboyina . aditya@stat.berkeley.edu . Ramesh Sridharan . ramesh_s@berkeley.edu . ",
    "url": "/fa23/staff/#instructors",
    
    "relUrl": "/staff/#instructors"
  },"43": {
    "doc": "Staff",
    "title": "Teaching Assistants",
    "content": "Alan Jian He/Him/His . alanjian131@berkeley.edu . Hi there, my name is Alan and I’m a 5th year MIDS student. When I’m not doing data things, I’m likely playing tennis, going on a run, or reading a book! . Dominic Liu He/Him/His . hangxingliu@berkeley.edu . Hi! I’m a master student in Statistics. Hope you’ll enjoy this class as much as I did. Jonathan Meshkanian He/Him/His . jmeshkanian@berkeley.edu . Hi, I’m a senior CS and Applied Math major, I love sports, especially basketball, music, video games, and poker. Feel free to reach out to me about anything! . Mariel Werner She/Her/Hers . mariel_werner@berkeley.edu . Hey I’m Mariel, PhD student studying theory of machine learning. I’m from Montana, love playing music, running, and want to start a company! . Nathan Harounian He/Him/His . nathanharounian@berkeley.edu . Hey! I’m a senior studying Statistics and Data Science. In my free time, I enjoy hanging out with my friends, listening to music, archery, and poker! I really enjoyed taking Data 102 last spring and look forward to helping y’all this fall :) . ",
    "url": "/fa23/staff/#teaching-assistants",
    
    "relUrl": "/staff/#teaching-assistants"
  },"44": {
    "doc": "Staff",
    "title": "UCS1",
    "content": "Evelyn Li She/Her/Hers . eve2018@berkeley.edu . Hi, let’s explore data 102 and food together! . Lulu Dai She/Her/Hers . luludai@berkeley.edu . Hey everyone! I’m a senior from SLO, CA studying Data Science &amp; Public Health. I love eating/cooking, crocheting, and cats! . Yehchan Yoo He/Him/His . yehchanyoo@berkeley.edu . Hello — I am a senior majoring in Statistics and Political Economy &amp; minoring in Data Science; I like to read the news, watch YouTube videos, listen to rock and electronic music, meditate, lift weights, and do boxing in my free time. Hope you all will enjoy the course, and always feel free to reach out! . ",
    "url": "/fa23/staff/#ucs1",
    
    "relUrl": "/staff/#ucs1"
  },"45": {
    "doc": "Syllabus",
    "title": "Syllabus",
    "content": "Jump to: . | About the Course | Prerequisites | Course Components . | Lectures | Discussion sessions | Lab | . | Grading Policies . | Assignments | Grading Scheme . | Grading criteria | . | Regrade requests | Exams | Slip Days | Extenuating Circumstances | DSP Accommodations | Collaboration Policy | . | Waitlist | We Want You to Succeed | Campus Honor Code | Device Lending options | Data Science Student Climate | Community Standards | . ",
    "url": "/fa23/syllabus/",
    
    "relUrl": "/syllabus/"
  },"46": {
    "doc": "Syllabus",
    "title": "About the Course",
    "content": "This course develops the probabilistic foundations of inference in data science. It builds a comprehensive view of the decision-making and modeling life cycle in data science, including its human, social, and ethical implications. Topics include: frequentist and Bayesian decision-making, permutation testing, false discovery rate, probabilistic interpretations of models, Bayesian hierarchical models, basics of experimental design, confidence intervals, causal inference, robustness, Thompson sampling, optimal control, Q-learning, differential privacy, fairness in classification, recommendation systems and an introduction to machine learning tools including decision trees, neural networks and ensemble methods. This class is listed as Data 102. ",
    "url": "/fa23/syllabus/#about-the-course",
    
    "relUrl": "/syllabus/#about-the-course"
  },"47": {
    "doc": "Syllabus",
    "title": "Prerequisites",
    "content": "While we are working to make this class widely accessible we currently require the following (or equivalent) prerequisites : . | Principles and Techniques of Data Science: Data 100 covers important computational and statistical skills that will be necessary for Data 102. | Probability: Probability for Data Science Data 140, or Probability and Random Processes EECS126, or Concepts of Probability STAT134, or Probability and Risk Analysis for Engineers IEOR 172, or Mathematical Probability Theory Math 106. EECS126 and Data 140 are preferred. These courses cover the probabilistic tools that will form the underpinning for the concepts covered in Data 102. | Math: Linear Algebra &amp; Differential Equations Math 54, or Linear Algebra Math 56, or Linear Algebra Math 110, or both Designing Information Devices and Systems I EE16A and Designing Information Devices and Systems II EE16B, or Linear Algebra for Data Science Stat 89a, or Introduction to Mathematical Physics PHYSICS89. We will need some basic concepts like linear operators, eigenvectors, derivatives, and integrals to enable statistical inference and derive new prediction algorithms. | . Please consult the Resources page for additional resources for reviewing prerequisite material. ",
    "url": "/fa23/syllabus/#prerequisites",
    
    "relUrl": "/syllabus/#prerequisites"
  },"48": {
    "doc": "Syllabus",
    "title": "Course Components",
    "content": "Lectures . Lectures will be held in-person Tuesdays and Thursdays from 3:30 - 5pm in Li Ka Shing 245. Recordings will be made available on bCourses within 24 hours. Discussion sessions . Discussion section will be held on Wednesdays, led by your GSIs. These sections will cover important problem-solving skills that bridge the concepts in the lecture with the skills you’ll need to apply the ideas on the homework and beyond. Lab . Labs will be held on Mondays in-person. You can complete lab assignments on your own time, but you are highly encouraged to attend lab sessions to work with your classmates and get help from the staff. ",
    "url": "/fa23/syllabus/#course-components",
    
    "relUrl": "/syllabus/#course-components"
  },"49": {
    "doc": "Syllabus",
    "title": "Grading Policies",
    "content": "Assignments . You will be assessed through the following assignments: . | (about) 14 weekly vitamins | 6 homework assignments | 12 lab assignments | 2 midterms | 1 final project | . Grading Scheme . Grades will be assigned using the following weighted components: . | Category | Percentage | Details | . | Vitamins | 5% | Drop 2 lowest scores | . | Homeworks | 20% | No drop; 5 slip days | . | Labs | 15% | Drop 2 lowest scores | . | Midterm 1 | 20% |   | . | Midterm 2 | 20% |   | . | Final project | 20% |   | . Grading criteria . | Vitamins are weekly short assignments to check that you are keeping up with lectures. Vitamins should take fewer than 15 minutes to complete. Your two lowest vitamin scores will be dropped. | Homework will be graded on completion and correctness. No assignment may be dropped, but we have a slip day policy (see below). | Lab assignments will be graded on completion and correctness, but all test cases for autograded questions will be public. Your two lowest lab scores will be dropped. | When submitting assignments on Gradescope, you must match each page to the corresponding question on Gradescope. If you fail to do so, you may not receive credit for your work! | A grading rubric and more details regarding the final project will be released later in the semester. | . Regrade requests . | After each assignment is graded, course staff will post the deadline for regrade requests for that assignment on Ed. | To ensure that our grading team is not overworked, regrade requests for each assignment must be submitted before the deadline (except in cases of emergencies). | Note: When you submit a regrade request, we will take a fresh look at the question, so it is possible that you will receive a grade lower that what you originally received. | . Exams . There will be two midterms in this class: . | Midterm 1 on October 5, 2023 7-9PM | Midterm 2 on November 14, 2023 7-9PM | . All exams must be taken in-person. You must take the midterm at the specified time: if you have a conflict, please contact course staff ASAP at data102@berkeley.edu. We will not accept any conflicts after the drop deadline (except for emergencies). Exams will be held in person. Further information will be communicated in due course. Slip Days . Each student gets an extension budget of 5 total slip days. You can use the extension on homework assignments only (not lab assignments, weekly vitamins, or the final project) during the semester. Some important notes on slip days: . | Do not plan to use your slip days: we’re providing them for unforeseen circumstances. | Slip days are self-serve: we’ll apply them to your assignments automatically. | Slip days are full days, not hours. We round up, so if you are 1 hour late, then 1 slip day will be used. (Why? We’d rather you get some sleep and make an attempt to finish the assignment the next day instead of staying up to micromanage hours.) | After you have used your slip-time budget, any assignment handed in late will be marked off 20% per day late (rounded up to the nearest integer number of days). | No assignment will be accepted more than 5 days late. | . Extenuating Circumstances . We recognize that our students come from varied backgrounds and have widely-varying experiences. If you encounter extenuating circumstances at any time in the semester, please do not hesitate to let us know. The sooner we are made aware, the more options we have available to us to help you. The Extenuating Circumstances Form is for any circumstances that cannot be resolved via slip days and drops. Within two business days of filling out the form, a course staff will reach out to you and provide a space for conversation, as well as to arrange course/grading accommodations as necessary. For more information, please email data102@berkeley.edu. We recognize that at times, it can be difficult to manage your course performance — particularly in such a huge course, and particularly at Berkeley’s high standards. Sometimes emergencies just come up (personal health emergency, family emergency, etc.). The Extenuating Circumstances Form is meant to lower the barrier to reaching out to us, as well as build your independence in managing your academic career long-term. So please do not hesitate to reach out. Note that extenuating circumstances do not extend to logistical oversight, such as Datahub/Gradescope tests not passing, submitting only one portion of the homework, forgetting to save your notebook before exporting, submitting to the wrong assignment portal, or not properly tagging pages on Gradescope. It is the student’s responsibility to identify and resolve these issues in advance of the deadlines. Additionally, extenuating circumstances do not extend to workload-related issues. It is the student’s responsibility to manage their other coursework and extracurricular commitments. We will not grant accommodations for these cases; instead, please use drops or slip days to cushion these issues. Lastly, make sure to submit extension requests before the assignment deadline. We will not entertain any extension requests made after assignment deadlines. Additionally, simply submitting a request does not guarantee you will receive an extension. Even if your work is incomplete, please submit before the deadline so you can receive credit for the work you did complete. DSP Accommodations . If you are registered with the Disabled Students’ Program (DSP) you can expect to receive an email from us during the first week of classes confirming your accommodations. Otherwise, email data102@berkeley.edu. DSP students who receive approved assignment accommodations will have a 2-day extension on homeworks and 1-day extension on labs and vitamins. Please note that any extension, plus slip days, cannot exceed 5 days. DSP students can submit assignment extension accommodation requests via the Extenuating Circumstances Form. You are responsible for reasonable communication with course staff. If you make a request close to the deadline, we can not guarantee that you will receive a response before the deadline. Collaboration Policy . Data science is a collaborative activity. While you may talk with others about the homework, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names at the top of your notebook. Keep in mind that content from the homeworks and labs will likely be covered on both of the midterms. We will be following the EECS departmental policy on Academic Honesty, so be sure you are familiar with it. ",
    "url": "/fa23/syllabus/#grading-policies",
    
    "relUrl": "/syllabus/#grading-policies"
  },"50": {
    "doc": "Syllabus",
    "title": "Waitlist",
    "content": "If you are on the waitlist, you should complete and submit all assignments as if enrolled: we will not offer any makeup assignments for waitlisted students. For all other enrollment related issues, please reach out to the Data Science advisors, as instructors and staff do not manage enrollment. ",
    "url": "/fa23/syllabus/#waitlist",
    
    "relUrl": "/syllabus/#waitlist"
  },"51": {
    "doc": "Syllabus",
    "title": "We Want You to Succeed",
    "content": "If you are feeling overwhelmed, visit our office hours and talk with us. We know college can be stressful and we want to help you succeed! . ",
    "url": "/fa23/syllabus/#we-want-you-to-succeed",
    
    "relUrl": "/syllabus/#we-want-you-to-succeed"
  },"52": {
    "doc": "Syllabus",
    "title": "Campus Honor Code",
    "content": "As a member of the Berkeley community, we expect you to follow the Berkeley Honor Code: . “As a member of the UC Berkeley community, I act with honesty, integrity, and respect for others.” . ",
    "url": "/fa23/syllabus/#campus-honor-code",
    
    "relUrl": "/syllabus/#campus-honor-code"
  },"53": {
    "doc": "Syllabus",
    "title": "Device Lending options",
    "content": "Students can access device lending options through the Student Technology Equity Program STEP program. ",
    "url": "/fa23/syllabus/#device-lending-options",
    
    "relUrl": "/syllabus/#device-lending-options"
  },"54": {
    "doc": "Syllabus",
    "title": "Data Science Student Climate",
    "content": "Data Science Undergraduate Studies faculty and staff are committed to creating a community where every person feels respected, included, and supported. We recognize that incidents may happen, sometimes unintentionally, that run counter to this goal. There are many things we can do to try to improve the climate for students, but we need to understand where the challenges lie. If you experience a remark, or disrespectful treatment, or if you feel you are being ignored, excluded or marginalized in a course or program-related activity, please speak up. Consider talking to your instructor, but you are also welcome to contact Executive Director Christina Teller at cpteller@berkeley.edu or report an incident anonymously through this online form. ",
    "url": "/fa23/syllabus/#data-science-student-climate",
    
    "relUrl": "/syllabus/#data-science-student-climate"
  },"55": {
    "doc": "Syllabus",
    "title": "Community Standards",
    "content": "Ed is a formal, academic space. We must demonstrate appropriate respect, consideration, and compassion for others. Please be friendly and thoughtful; our community draws from a wide spectrum of valuable experiences. For further reading, please reference Berkeley’s Principles of Community and the Berkeley Campus Code of Student Conduct. ",
    "url": "/fa23/syllabus/#community-standards",
    
    "relUrl": "/syllabus/#community-standards"
  }
}
