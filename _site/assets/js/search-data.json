{"0": {
    "doc": "Staff Pictures",
    "title": "Staff Pictures",
    "content": "Staff pictures go here . ",
    "url": "/fa23/resources/assets/staff_pics/README/",
    
    "relUrl": "/resources/assets/staff_pics/README/"
  },"1": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": "Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"2": {
    "doc": "Announcements",
    "title": "Week 15",
    "content": "Nov 27 . | Midterm 2 grades are released. Regrade requests are due Sunday, Dec 3rd. | Lab 12 is due Wednesday, Nov 29th 11:59PM. | Homework 6 is due Friday, Dec 1st 5:00PM. | Homework Party Tuesday, Nov 28th 5-7PM in Warren 101B. | . | Project Checkpoint 1 is due Wednesday, Nov 29th. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"3": {
    "doc": "Announcements",
    "title": "Week 14",
    "content": "Nov 20 . | Feedbacks for project proposals have been released on Gradescope. Check the comments in your submission and #494. | Project checkpoints are now extended: . | Checkpoint 1 is due next Wednesday, 11/29 | Checkpoint 2 is due Tuesday of RRR week, 12/5 | . | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"4": {
    "doc": "Announcements",
    "title": "Week 13",
    "content": "Nov 13 . | Midterm 2 is Tuesday, Nov 14th. You should’ve received your seating assignment via email. | Some schedule changes have been made for the week, check #425 and the calendar for details. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"5": {
    "doc": "Announcements",
    "title": "Week 12",
    "content": "Nov 6 . | Lab 10 is due Wednesday, Nov 8th 11:59PM. | Homework 5 is now optional. | Project Proposal is due this Friday, Nov 10th 11:59PM. | Midterm 2 is next Tuesday, Nov 14th 7 - 9PM. | We will hold a review session this Thursday, Nov 9th 5 - 7PM in Moffitt 101. | . | Some schedule changes have been made for the following week, check #425 and the calendar for details. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"6": {
    "doc": "Announcements",
    "title": "Week 11",
    "content": "Oct 29 . | Lab 9 is released and due Wednesday, Nov 1st at 11:59PM. | Homework 4 is released and due Friday, Nov 3rd at 5PM. | Homework Party will be held Tuesday, Oct 31st 5-7PM in Warren 101B. | . | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"7": {
    "doc": "Announcements",
    "title": "Week 10",
    "content": "Oct 23 . | Lab 8 is released and due Wednesday, Oct 25th at 11:59PM. | Homework 4 is released and due Friday, Nov 3rd at 5PM. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"8": {
    "doc": "Announcements",
    "title": "Week 9",
    "content": "Oct 16 . | Midterm 1 regrade is due Wednesday, Oct 18th 11:59PM. | Lab 7 is released and due Wednesday, Oct 18th at 11:59PM. | Homework 3 is due Friday, Oct 20th at 5PM. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"9": {
    "doc": "Announcements",
    "title": "Week 8",
    "content": "Oct 9 . | Congratulations on finishing Midterm 1! | Lab 6 is released and due Wednesday, 10/11 at 11:59PM. | Homework 3 is released and due Friday, 10/20 at 5PM. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"10": {
    "doc": "Announcements",
    "title": "Week 7",
    "content": "Oct 3 . | Midterm 1 is this Thursday 7-9PM. | Review session Tuesday 5-7PM in Moffitt 101. | Check Ed for detailed logistics. | . | Lab 5 is due Wednesday 11:59PM. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"11": {
    "doc": "Announcements",
    "title": "Week 6",
    "content": "Sep 25 . | Lab 4 is released and due Wednesday 11:59PM. | Homework 2 is due this Friday 5:00PM. | Homework Party will be held Tuesday 5-7PM in Warren 101B Section A. | . | Midterm 1 is next week. Check Ed for detailed logistics. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"12": {
    "doc": "Announcements",
    "title": "Week 5",
    "content": "Sep 18 . | Lab 3 is released and due Wednesday 11:59PM. | Homework 2 is released and due next Friday 5:00PM. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"13": {
    "doc": "Announcements",
    "title": "Week 4",
    "content": "Sep 11 . | Homework 1 is due this Friday at 5PM. | Homework Party will be Tuesday 5-7PM in Warren 101B Section A. | Office hours are updated. Check the calendar page for the most up-to-date schedule. | . | Lab 2 is released and due Wednesday 11:59PM. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"14": {
    "doc": "Announcements",
    "title": "Week 3",
    "content": "Sep 3 . | Monday is Labor Day: no class activity (lab sections, office hours). As a result, Lab 1 due date is extended to Friday, Sep 8. | Discussion sections schedule is slightly modified. Check the calendar page for more details. | Supplemental section starts this Wednesday. Check the calendar page for location and time. | Fill out the Exam Conflict Form if any exam conflicts with your other commitments. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"15": {
    "doc": "Announcements",
    "title": "Week 2",
    "content": "Aug 28 . | Lab and Discussion sections start this week! Check the calendar page for times and locations. | Fill out the Exam Conflict Form if one of the exams conflict with your other commitments. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"16": {
    "doc": "Announcements",
    "title": "Week 1",
    "content": "Aug 23 . | Welcome to Data 102! The first lecture will be on Thursday, August 24th, from 3:30PM - 5PM in Li Ka Shing 245. | Please carefully read through the course policies, which covers the details of the course this fall. | . ",
    "url": "/fa23/announcements/",
    
    "relUrl": "/announcements/"
  },"17": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": "All course events are listed in the following calendar. Click on the events to check the locations. ",
    "url": "/fa23/calendar/",
    
    "relUrl": "/calendar/"
  },"18": {
    "doc": "Home",
    "title": "Data 102: Data, Inference, and Decisions",
    "content": "UC Berkeley, Fall 2023 . Aditya Guntuboyina . aditya@stat.berkeley.edu . Ramesh Sridharan . ramesh_s@berkeley.edu . ",
    "url": "/fa23/#data-102-data-inference-and-decisions",
    
    "relUrl": "/#data-102-data-inference-and-decisions"
  },"19": {
    "doc": "Home",
    "title": "Week 15",
    "content": "Nov 27 . | Midterm 2 grades are released. Regrade requests are due Sunday, Dec 3rd. | Lab 12 is due Wednesday, Nov 29th 11:59PM. | Homework 6 is due Friday, Dec 1st 5:00PM. | Homework Party Tuesday, Nov 28th 5-7PM in Warren 101B. | . | Project Checkpoint 1 is due Wednesday, Nov 29th. | . ",
    "url": "/fa23/",
    
    "relUrl": "/"
  },"20": {
    "doc": "Home",
    "title": "Schedule",
    "content": "Jump to current week . ",
    "url": "/fa23/#schedule",
    
    "relUrl": "/#schedule"
  },"21": {
    "doc": "Home",
    "title": "Week 1: Introductions",
    "content": "Aug 24 Lecture 1 Course Overview Vitamin Vitamin 1 (due Aug 27 Aug 28) ",
    "url": "/fa23/#week-1-introductions",
    
    "relUrl": "/#week-1-introductions"
  },"22": {
    "doc": "Home",
    "title": "Week 2: Decisions I",
    "content": "Aug 28 Lab 0 Review and Warm-up (due Aug 30) Aug 29 Lecture 2 Binary Decision-Making Aug 30 Discussion Discussion 1 Solution Aug 31 Lecture 3 \\(p\\)-Values and Multiple Hypothesis Testing Vitamin Vitamin 2 (due Sep 3) Sep 1 Homework Homework 1 (PDF) (due Sep 15 5 PM) ",
    "url": "/fa23/#week-2-decisions-i",
    
    "relUrl": "/#week-2-decisions-i"
  },"23": {
    "doc": "Home",
    "title": "Week 3: Decisions II",
    "content": "Sep 4 Lab 1 Basics of Testing (due Sep 6 Sep 8) Sep 5 Lecture 4 Online False Discovery Rate Control &amp; ROC curves Sep 6 Discussion Discussion 2 Solution Sep 7 Lecture 5 Frequentist vs. Bayesian Decision-Making Vitamin Vitamin 3 (due Sep 10) ",
    "url": "/fa23/#week-3-decisions-ii",
    
    "relUrl": "/#week-3-decisions-ii"
  },"24": {
    "doc": "Home",
    "title": "Week 4: Bayesian Modeling I",
    "content": "Sep 11 Lab 2 Loss and Risk (due Sep 13) Sep 12 Lecture 6 Overview of Bayesian Modeling Sep 13 Discussion Discussion 3 Solutions Sep 14 Lecture 7 Beta-Binomial Inference Vitamin Vitamin 4 (due Sep 17) Sep 15 Homework Homework 2 (PDF) (due Sep 29 5 PM) ",
    "url": "/fa23/#week-4-bayesian-modeling-i",
    
    "relUrl": "/#week-4-bayesian-modeling-i"
  },"25": {
    "doc": "Home",
    "title": "Week 5: Bayesian Modeling II",
    "content": "Sep 18 Lab 3 Bayesian Estimation in Hierarchical Graphical Models (due Sep 20) Sep 19 Lecture 8 Graphical Models, PyMC Sep 20 Discussion Discussion 4 Solution Sep 21 Lecture 9 More PyMC, Rejection Sampling Vitamin Vitamin 5 (due Sep 24) ",
    "url": "/fa23/#week-5-bayesian-modeling-ii",
    
    "relUrl": "/#week-5-bayesian-modeling-ii"
  },"26": {
    "doc": "Home",
    "title": "Week 6: GLM I",
    "content": "Sep 25 Lab 4 Rejection Sampling, More PyMC (due Sep 27) Sep 26 Lecture 10 Gibbs Sampling, Linear Regression Sep 27 Discussion Discussion 5 Solution Sep 28 Lecture 11 Generalized Linear Models Vitamin Vitamin 6 (due Oct 1) ",
    "url": "/fa23/#week-6-glm-i",
    
    "relUrl": "/#week-6-glm-i"
  },"27": {
    "doc": "Home",
    "title": "Week 7: GLM II",
    "content": "Oct 2 Lab 5 Gibbs Sampling and GLM (due Oct 4) Oct 3 Lecture 12 Model Selection and Model Checking for GLMs Oct 4 Discussion Discussion 6 Solution Oct 5 Midterm Midterm 1 (7-9 PM) Oct 6 Homework Homework 3 (PDF) (due Oct 20) ",
    "url": "/fa23/#week-7-glm-ii",
    
    "relUrl": "/#week-7-glm-ii"
  },"28": {
    "doc": "Home",
    "title": "Week 8: Machine Learning",
    "content": "Oct 9 Lab 6 Model Selection and Uncertainty Quantification with GLMs (due Oct 11) Oct 10 Lecture 13 Nonparametric Methods Oct 11 Discussion Discussion 7 Solutions Oct 12 Lecture 14 Neural Networks Vitamin Vitamin 7 (due Oct 15) ",
    "url": "/fa23/#week-8-machine-learning",
    
    "relUrl": "/#week-8-machine-learning"
  },"29": {
    "doc": "Home",
    "title": "Week 9: Causal Inference I",
    "content": "Oct 16 Lab 7 Nonparametric Methods (due Oct 18) Oct 17 Lecture 15 Causal Inference 1: Association and Causation Oct 18 Discussion Discussion 8 Solutions Oct 19 Lecture 16 Causal Inference 2: Randomized Experiments Vitamin Vitamin 8 (due Oct 22) Oct 20 Homework Homework 4 (PDF) (due Nov 3) ",
    "url": "/fa23/#week-9-causal-inference-i",
    
    "relUrl": "/#week-9-causal-inference-i"
  },"30": {
    "doc": "Home",
    "title": "Week 10: Causal Inference II",
    "content": "Oct 23 Lab 8 Causal Inference via Instrumental Variables (due Oct 25) Oct 24 Lecture 17 Causal Inference 3: Observational Studies Oct 25 Discussion Discussion 9 Solution Oct 26 Lecture 18 Concentration Inequalities Vitamin Vitamin 9 (due Oct 29) ",
    "url": "/fa23/#week-10-causal-inference-ii",
    
    "relUrl": "/#week-10-causal-inference-ii"
  },"31": {
    "doc": "Home",
    "title": "Week 11: Bandits",
    "content": "Oct 30 Lab 9 Causal Inference via Unconfoundedness (due Nov 1) Oct 31 Lecture 19 Bandits I Project Final Project Release Guidelines, Grading Rubrics Nov 1 Discussion Discussion 10 Solution Nov 2 Lecture 20 Bandits II Vitamin Vitamin 10 (due Nov 5) Nov 3 Homework Homework 5 (PDF) (Optional, not due Nov 10) ",
    "url": "/fa23/#week-11-bandits",
    
    "relUrl": "/#week-11-bandits"
  },"32": {
    "doc": "Home",
    "title": "Week 12: Reinforcement Learning",
    "content": "Nov 6 Lab 10 Bandits (due Nov 8) Nov 7 Lecture 21 Reinforcement Learning I Nov 8 Discussion Discussion 11 Solution Nov 9 Lecture 22 Reinforcement Learning II Vitamin Vitamin 11 (due Nov 12) Nov 10 Project Project Proposal Due ",
    "url": "/fa23/#week-12-reinforcement-learning",
    
    "relUrl": "/#week-12-reinforcement-learning"
  },"33": {
    "doc": "Home",
    "title": "Week 13: Regression revisited",
    "content": "Nov 14 Midterm Midterm 2 (7-9 PM) Reference Sheet Nov 16 Lecture 23 High-dimensional regression Vitamin Vitamin 12 (due Nov 19) Nov 17 Homework Homework 6 (Corrected PDF) (due Dec 1) ",
    "url": "/fa23/#week-13-regression-revisited",
    
    "relUrl": "/#week-13-regression-revisited"
  },"34": {
    "doc": "Home",
    "title": "Week 14: Privacy",
    "content": "Nov 20 Lab 11 Reinforcement Learning (due Nov 22) Nov 21 Lecture 24 Differential Privacy Nov 23 Thanksgiving ",
    "url": "/fa23/#week-14-privacy",
    
    "relUrl": "/#week-14-privacy"
  },"35": {
    "doc": "Home",
    "title": "Week 15: Wrap-Up",
    "content": "Nov 27 Lab 12 Differential Privacy (due Nov 29) Nov 28 Lecture 25 Case Study: Robustness and generalization Nov 29 Discussion Discussion 12 Project Project Checkpoint 1 Due Nov 30 Lecture 26 Course Wrap-Up ",
    "url": "/fa23/#week-15-wrap-up",
    
    "relUrl": "/#week-15-wrap-up"
  },"36": {
    "doc": "Home",
    "title": "Week 16: RRR Week",
    "content": "Dec 4 Office Hour Dec 5 Office Hour Project Project Checkpoint 2 Due Dec 6 Office Hour Dec 7 Office Hour ",
    "url": "/fa23/#week-16-rrr-week",
    
    "relUrl": "/#week-16-rrr-week"
  },"37": {
    "doc": "Home",
    "title": "Week 16: Finals Week",
    "content": "Dec 11 Project Project Writeup Due ",
    "url": "/fa23/#week-16-finals-week",
    
    "relUrl": "/#week-16-finals-week"
  },"38": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/fa23/",
    
    "relUrl": "/"
  },"39": {
    "doc": "Lecture 1 – Course Overview",
    "title": "Lecture 1 – Introduction",
    "content": "Presented by Ramesh Sridharan . | Slides (PDF, Annotated) | Recording | Optional reading . | Artificial Intelligence — The Revolution Hasn’t Happened Yet | What are the most important statistical ideas of the past 50 years? | . | . ",
    "url": "/fa23/lecture/lec01/#lecture-1--introduction",
    
    "relUrl": "/lecture/lec01/#lecture-1--introduction"
  },"40": {
    "doc": "Lecture 1 – Course Overview",
    "title": "Lecture 1 – Course Overview",
    "content": " ",
    "url": "/fa23/lecture/lec01/",
    
    "relUrl": "/lecture/lec01/"
  },"41": {
    "doc": "Lecture 2 - Binary Decision Making, Multiple Decisions, Error Rates, and p-Values",
    "title": "Lecture 2 - Binary Decision Making, Multiple Decisions, Error Rates, and \\(p\\)-Values",
    "content": "Presented by Ramesh Sridharan . | Slides (PDF, Annotated) | Recording | Optional reading for next class . | The Garden of Forking Paths | . | . ",
    "url": "/fa23/lecture/lec02/#lecture-2---binary-decision-making-multiple-decisions-error-rates-and-p-values",
    
    "relUrl": "/lecture/lec02/#lecture-2---binary-decision-making-multiple-decisions-error-rates-and-p-values"
  },"42": {
    "doc": "Lecture 2 - Binary Decision Making, Multiple Decisions, Error Rates, and p-Values",
    "title": "Lecture 2 - Binary Decision Making, Multiple Decisions, Error Rates, and p-Values",
    "content": " ",
    "url": "/fa23/lecture/lec02/",
    
    "relUrl": "/lecture/lec02/"
  },"43": {
    "doc": "Lecture 3 - p-Values and Multiple Hypothesis Testing",
    "title": "Lecture 3 - \\(p\\)-Values and Multiple Hypothesis Testing",
    "content": "Presented by Ramesh Sridharan . | Slides (PDF, Annotated) | Demo | Recording | Partial proof of why B-H controls FDR (login to YouTube with your Berkeley email) | Optional reading . | The Garden of Forking Paths | . | . ",
    "url": "/fa23/lecture/lec03/#lecture-3---p-values-and-multiple-hypothesis-testing",
    
    "relUrl": "/lecture/lec03/#lecture-3---p-values-and-multiple-hypothesis-testing"
  },"44": {
    "doc": "Lecture 3 - p-Values and Multiple Hypothesis Testing",
    "title": "Lecture 3 - p-Values and Multiple Hypothesis Testing",
    "content": " ",
    "url": "/fa23/lecture/lec03/",
    
    "relUrl": "/lecture/lec03/"
  },"45": {
    "doc": "Lecture 4 - Online Decision-making and Binary Classification",
    "title": "Lecture 4 - Online Decision-making and Binary Classification",
    "content": "Presented by Ramesh Sridharan . | Slides (PDF, Annotated) | Demo | Recording | . ",
    "url": "/fa23/lecture/lec04/",
    
    "relUrl": "/lecture/lec04/"
  },"46": {
    "doc": "Lecture 5 - Decision Theory",
    "title": "Lecture 5 - Decision Theory",
    "content": "Presented by Ramesh Sridharan . | Slides (PDF, Annotated) | Demo | Recording | . ",
    "url": "/fa23/lecture/lec05/",
    
    "relUrl": "/lecture/lec05/"
  },"47": {
    "doc": "Lecture 6 - Overview of Bayesian Modeling",
    "title": "Lecture 6 - Overview of Bayesian Modeling",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | Handwritten Notes . | In-class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec06/",
    
    "relUrl": "/lecture/lec06/"
  },"48": {
    "doc": "Lecture 7 - Beta-Binomial Inference",
    "title": "Lecture 7: Beta-Binomial Inference",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | The interactive maps are not showing up in the HTML files; you can access them using the Jupyter Notebook, or through the following links . | Death Rates using naive proportions | Death Rates using Bayes estimates | . | . | Plots of Beta density used in class: Plot 1, Plot 2 . | Handwritten Notes . | In-Class Demo . | Recording | . ",
    "url": "/fa23/lecture/lec07/#lecture-7-beta-binomial-inference",
    
    "relUrl": "/lecture/lec07/#lecture-7-beta-binomial-inference"
  },"49": {
    "doc": "Lecture 7 - Beta-Binomial Inference",
    "title": "Lecture 7 - Beta-Binomial Inference",
    "content": " ",
    "url": "/fa23/lecture/lec07/",
    
    "relUrl": "/lecture/lec07/"
  },"50": {
    "doc": "Lecture 8 - Graphical Models and PyMC",
    "title": "Lecture 8: Graphical Models and PyMC",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | Handwritten Notes . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec08/#lecture-8-graphical-models-and-pymc",
    
    "relUrl": "/lecture/lec08/#lecture-8-graphical-models-and-pymc"
  },"51": {
    "doc": "Lecture 8 - Graphical Models and PyMC",
    "title": "Lecture 8 - Graphical Models and PyMC",
    "content": " ",
    "url": "/fa23/lecture/lec08/",
    
    "relUrl": "/lecture/lec08/"
  },"52": {
    "doc": "Lecture 9 - More PyMC, Rejection Sampling",
    "title": "Lecture 9: More PyMC, Rejection Sampling",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | Handwritten Notes . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec09/#lecture-9-more-pymc-rejection-sampling",
    
    "relUrl": "/lecture/lec09/#lecture-9-more-pymc-rejection-sampling"
  },"53": {
    "doc": "Lecture 9 - More PyMC, Rejection Sampling",
    "title": "Lecture 9 - More PyMC, Rejection Sampling",
    "content": " ",
    "url": "/fa23/lecture/lec09/",
    
    "relUrl": "/lecture/lec09/"
  },"54": {
    "doc": "Lecture 10 - Gibbs Sampling, Linear Regression",
    "title": "Lecture 10: Gibbs Sampling, Linear Regression",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec10/#lecture-10-gibbs-sampling-linear-regression",
    
    "relUrl": "/lecture/lec10/#lecture-10-gibbs-sampling-linear-regression"
  },"55": {
    "doc": "Lecture 10 - Gibbs Sampling, Linear Regression",
    "title": "Lecture 10 - Gibbs Sampling, Linear Regression",
    "content": " ",
    "url": "/fa23/lecture/lec10/",
    
    "relUrl": "/lecture/lec10/"
  },"56": {
    "doc": "Lecture 11 - Generalized Linear Models",
    "title": "Lecture 11: Generalized Linear Models",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) | In-Class Demo . | Recording | . ",
    "url": "/fa23/lecture/lec11/#lecture-11-generalized-linear-models",
    
    "relUrl": "/lecture/lec11/#lecture-11-generalized-linear-models"
  },"57": {
    "doc": "Lecture 11 - Generalized Linear Models",
    "title": "Lecture 11 - Generalized Linear Models",
    "content": " ",
    "url": "/fa23/lecture/lec11/",
    
    "relUrl": "/lecture/lec11/"
  },"58": {
    "doc": "Lecture 12 - Model Selection and Model Checking for GLMs",
    "title": "Lecture 12: Model Selection and Model Checking for GLMs",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec12/#lecture-12-model-selection-and-model-checking-for-glms",
    
    "relUrl": "/lecture/lec12/#lecture-12-model-selection-and-model-checking-for-glms"
  },"59": {
    "doc": "Lecture 12 - Model Selection and Model Checking for GLMs",
    "title": "Lecture 12 - Model Selection and Model Checking for GLMs",
    "content": " ",
    "url": "/fa23/lecture/lec12/",
    
    "relUrl": "/lecture/lec12/"
  },"60": {
    "doc": "Lecture 13 - Nonparametric Methods",
    "title": "Lecture 13: Nonparametric Methods",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec13/#lecture-13-nonparametric-methods",
    
    "relUrl": "/lecture/lec13/#lecture-13-nonparametric-methods"
  },"61": {
    "doc": "Lecture 13 - Nonparametric Methods",
    "title": "Lecture 13 - Nonparametric Methods",
    "content": " ",
    "url": "/fa23/lecture/lec13/",
    
    "relUrl": "/lecture/lec13/"
  },"62": {
    "doc": "Lecture 14 - Neural Networks",
    "title": "Lecture 14: Neural Networks",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec14/#lecture-14-neural-networks",
    
    "relUrl": "/lecture/lec14/#lecture-14-neural-networks"
  },"63": {
    "doc": "Lecture 14 - Neural Networks",
    "title": "Lecture 14 - Neural Networks",
    "content": " ",
    "url": "/fa23/lecture/lec14/",
    
    "relUrl": "/lecture/lec14/"
  },"64": {
    "doc": "Lecture 16 - Causal Inference 1, Association and Causation",
    "title": "Lecture 15: Causal Inference 1, Association and Causation",
    "content": "Presented by Ramesh Sridharan . | Required reading for Lecture 16: Discrimination in hiring article (pdf) and skim the paper | Slides (PDF, annotated) | Lecture Notes 1: Association, correlation, and causation | Lecture Notes 2: Quantifying association | Lecture Notes 3: Causality and Potential Outcomes | Recording | . ",
    "url": "/fa23/lecture/lec15/#lecture-15-causal-inference-1-association-and-causation",
    
    "relUrl": "/lecture/lec15/#lecture-15-causal-inference-1-association-and-causation"
  },"65": {
    "doc": "Lecture 16 - Causal Inference 1, Association and Causation",
    "title": "Lecture 16 - Causal Inference 1, Association and Causation",
    "content": " ",
    "url": "/fa23/lecture/lec15/",
    
    "relUrl": "/lecture/lec15/"
  },"66": {
    "doc": "Lecture 16 - Causal Inference 2, Randomized Experiments",
    "title": "Lecture 16: Causal Inference 2, Randomized Experiments",
    "content": "Presented by Ramesh Sridharan . | Required reading: Discrimination in hiring article (pdf) and skim the paper | Slides (PDF, annotated) | Lecture Notes: Causality and Potential Outcomes | Lecture Notes: Randomized Experiments | Lecture Notes: Instrumental Variables . | Recording | . ",
    "url": "/fa23/lecture/lec16/#lecture-16-causal-inference-2-randomized-experiments",
    
    "relUrl": "/lecture/lec16/#lecture-16-causal-inference-2-randomized-experiments"
  },"67": {
    "doc": "Lecture 16 - Causal Inference 2, Randomized Experiments",
    "title": "Lecture 16 - Causal Inference 2, Randomized Experiments",
    "content": " ",
    "url": "/fa23/lecture/lec16/",
    
    "relUrl": "/lecture/lec16/"
  },"68": {
    "doc": "Lecture 17 - Causal Inference 3, Observational Studies",
    "title": "Lecture 17: Causal Inference 3, Observational Studies",
    "content": "Presented by Ramesh Sridharan . | Slides (PDF, annotated) . | Lecture Notes: Observational Studies and Unconfoundedness . | Recording . | . ",
    "url": "/fa23/lecture/lec17/#lecture-17-causal-inference-3-observational-studies",
    
    "relUrl": "/lecture/lec17/#lecture-17-causal-inference-3-observational-studies"
  },"69": {
    "doc": "Lecture 17 - Causal Inference 3, Observational Studies",
    "title": "Lecture 17 - Causal Inference 3, Observational Studies",
    "content": " ",
    "url": "/fa23/lecture/lec17/",
    
    "relUrl": "/lecture/lec17/"
  },"70": {
    "doc": "Lecture 18 - Concentration Inequalities",
    "title": "Lecture 18: Concentration Inequalities",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | Handwritten Notes . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec18/#lecture-18-concentration-inequalities",
    
    "relUrl": "/lecture/lec18/#lecture-18-concentration-inequalities"
  },"71": {
    "doc": "Lecture 18 - Concentration Inequalities",
    "title": "Lecture 18 - Concentration Inequalities",
    "content": " ",
    "url": "/fa23/lecture/lec18/",
    
    "relUrl": "/lecture/lec18/"
  },"72": {
    "doc": "Lecture 19 - Bandits I",
    "title": "Lecture 19: Bandits I",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | Handwritten Notes . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec19/#lecture-19-bandits-i",
    
    "relUrl": "/lecture/lec19/#lecture-19-bandits-i"
  },"73": {
    "doc": "Lecture 19 - Bandits I",
    "title": "Lecture 19 - Bandits I",
    "content": " ",
    "url": "/fa23/lecture/lec19/",
    
    "relUrl": "/lecture/lec19/"
  },"74": {
    "doc": "Lecture 20 - Bandits II",
    "title": "Lecture 20: Bandits II",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | Handwritten Notes . | Recording . | . ",
    "url": "/fa23/lecture/lec20/#lecture-20-bandits-ii",
    
    "relUrl": "/lecture/lec20/#lecture-20-bandits-ii"
  },"75": {
    "doc": "Lecture 20 - Bandits II",
    "title": "Lecture 20 - Bandits II",
    "content": " ",
    "url": "/fa23/lecture/lec20/",
    
    "relUrl": "/lecture/lec20/"
  },"76": {
    "doc": "Lecture 21 - Reinforcement Learning I",
    "title": "Lecture 21: Reinforcement Learning I",
    "content": "Presented by Ramesh Sridharan . | Slides . | Lecture Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec21/#lecture-21-reinforcement-learning-i",
    
    "relUrl": "/lecture/lec21/#lecture-21-reinforcement-learning-i"
  },"77": {
    "doc": "Lecture 21 - Reinforcement Learning I",
    "title": "Lecture 21 - Reinforcement Learning I",
    "content": " ",
    "url": "/fa23/lecture/lec21/",
    
    "relUrl": "/lecture/lec21/"
  },"78": {
    "doc": "Lecture 22 - Reinforcement Learning II",
    "title": "Lecture 22: Reinforcement Learning II",
    "content": "Presented by Ramesh Sridharan . | Slides . | Lecture Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec22/#lecture-22-reinforcement-learning-ii",
    
    "relUrl": "/lecture/lec22/#lecture-22-reinforcement-learning-ii"
  },"79": {
    "doc": "Lecture 22 - Reinforcement Learning II",
    "title": "Lecture 22 - Reinforcement Learning II",
    "content": " ",
    "url": "/fa23/lecture/lec22/",
    
    "relUrl": "/lecture/lec22/"
  },"80": {
    "doc": "Lecture 23 - High-Dimensional Regression",
    "title": "Lecture 23: High-Dimensional Regression",
    "content": "Presented by Aditya Guntuboyina . | Lecture Notes (HTML) . | In-Class Demo . | Recording . | . ",
    "url": "/fa23/lecture/lec23/#lecture-23-high-dimensional-regression",
    
    "relUrl": "/lecture/lec23/#lecture-23-high-dimensional-regression"
  },"81": {
    "doc": "Lecture 23 - High-Dimensional Regression",
    "title": "Lecture 23 - High-Dimensional Regression",
    "content": " ",
    "url": "/fa23/lecture/lec23/",
    
    "relUrl": "/lecture/lec23/"
  },"82": {
    "doc": "Lecture 24 - Privacy in Machine Learning",
    "title": "Lecture 24: Privacy in Machine Learning",
    "content": "Presented by Ramesh Sridharan . | Demo notebook . | Slides . | Recording . | . ",
    "url": "/fa23/lecture/lec24/#lecture-24-privacy-in-machine-learning",
    
    "relUrl": "/lecture/lec24/#lecture-24-privacy-in-machine-learning"
  },"83": {
    "doc": "Lecture 24 - Privacy in Machine Learning",
    "title": "Lecture 24 - Privacy in Machine Learning",
    "content": " ",
    "url": "/fa23/lecture/lec24/",
    
    "relUrl": "/lecture/lec24/"
  },"84": {
    "doc": "Lecture 25 - Case Studies Generalization and Robustness",
    "title": "Lecture 25: Case Studies: Generalization and Robustness",
    "content": "Presented by Ramesh Sridharan . | Slides . | Recording . | . ",
    "url": "/fa23/lecture/lec25/#lecture-25-case-studies-generalization-and-robustness",
    
    "relUrl": "/lecture/lec25/#lecture-25-case-studies-generalization-and-robustness"
  },"85": {
    "doc": "Lecture 25 - Case Studies Generalization and Robustness",
    "title": "Lecture 25 - Case Studies Generalization and Robustness",
    "content": " ",
    "url": "/fa23/lecture/lec25/",
    
    "relUrl": "/lecture/lec25/"
  },"86": {
    "doc": "Resources",
    "title": "Resources",
    "content": "Here is a collection of resources that will help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these and other materials. If you find something helpful, post it on EdStem, and consider contributing it to the course website. Jump to: . | Exam Resources | Web References | Textbooks from Previous Data Science Courses | Reading Resources | . ",
    "url": "/fa23/resources/",
    
    "relUrl": "/resources/"
  },"87": {
    "doc": "Resources",
    "title": "Exam Resources",
    "content": "| Semester | Midterm (1) | Midterm 2 | Final | . | Fall 2023 | Exam (Solutions) | Exam (Solutions) |   | . | Spring 2023 | Exam (Solutions) | Exam (Solutions) |   | . | Fall 2022 | Exam (Solutions) | Exam (Solutions) |   | . | Spring 2022 | Exam (Solutions) | Exam (Solutions) |   | . | Fall 2021 | Exam (Solutions) | Exam (Solutions) |   | . | Spring 2021 | Exam (Solutions) | Exam (Solutions) |   | . | Fall 2020 | Exam (Solutions) |   | Exam (Solutions) | . | Spring 2020 | Exam (Solutions) |   |   | . | Fall 2019 | Exam (Solutions) |   | Exam (Solutions) | . Here is a collection of resources that may help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well-rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these materials. ",
    "url": "/fa23/resources/#exam-resources",
    
    "relUrl": "/resources/#exam-resources"
  },"88": {
    "doc": "Resources",
    "title": "Web References",
    "content": "In this class we will be using several key libraries. Here are their documentation pages: . | Python: . | Python Tutorial: Teach yourself python. This is a pretty comprehensive tutorial. | Python + Numpy Tutorial this tutorial provides a great overview of a lot of the functionality we will be using in DS102. | Python 101: A notebook demonstrating a lot of python functionality with some (minimal explanation). | . | Plotting: . | matplotlib.pyplot tutorial: This short tutorial provides an overview of the basic plotting utilities we will be using. | seaborn: The Seaborn library has some nice additional visualization functions that we may use occasionally. | . | Pandas: . | The Pandas Cookbook: This provides a nice overview of some of the basic Pandas functions. However, it is slightly out of date. | Learn Pandas A set of lessons providing an overview of the Pandas library. | Python for Data Science Another set of notebook demonstrating Pandas functionality. | Python for Data Analysis (Available as eBook for Berkeley students). This book provides a good reference for the Pandas library. | . | . ",
    "url": "/fa23/resources/#web-references",
    
    "relUrl": "/resources/#web-references"
  },"89": {
    "doc": "Resources",
    "title": "Textbooks from Previous Data Science Courses",
    "content": "Data 102 builds on material taught in previous data science courses. You may find the textbooks from those courses helpful: . | Data 8 | Data 100 | Data 140: even if you took one of the other probability prerequisite courses, this book can be a helpful reference. | . ",
    "url": "/fa23/resources/#textbooks-from-previous-data-science-courses",
    
    "relUrl": "/resources/#textbooks-from-previous-data-science-courses"
  },"90": {
    "doc": "Resources",
    "title": "Reading Resources",
    "content": ". | Data 102 Textbook Because data science is a relatively new and rapidly evolving discipline there is no single ideal textbook for this subject. The instructors are in the process of developing this online textbook for the course, they will be updating the textbook as semester progresses. You can also find useful reading among the following collection of books, all of which are free . | Patterns, Predictions, and Actions This book is a great introduction to many of the topics we cover in this course, as well as several other important topics in advanced machine learning and data science. The following chapters are particularly relevant to this class: . | Chapter 2 covers decision theory. | Chapter 8 covers datasets: even though we won’t be talking about this much in Data 102, this is an extremely important topic to know about for doing real-world data science. | Chapters 9 and 10 cover causal inference. | Chapter 12 covers reinforcement learning. | . | Statistical Rethinking This popular online graduate course is an excellent introduction to thinking about statistics through a Bayesian and causal lens. While it goes into much more detail than Data 102 does, lectures 2, 5, and 8 are all closely related to what we cover. | All of Statistics This book is a great, broad introduction to mathematical statistics. It begins with probability concepts (e.g. Bayes’ theorem), works through many statistical inference topics (e.g. hypothesis testing, decision theory, and bootstrap, and also includes statistical modeling (e.g. regression and causal inference)). The textbook as a whole covers many more ideas from statistics than will be used in or needed for this course, but students may still find it useful to reference specific topics within it to supplement ideas covered in lecture or review ideas from previous courses. For example: . | Chapters 1-3 review some background ideas about probability and random variables | Chapter 12 discusses the statistical decision theory framework | Section 9.3 reviews maximum likelihood estimation, while the first few sections of chapter 11 review the core idea behind Bayesian inference | Sections 10.2, 10.6, and 10.7 cover p-values, the likelihood ratio test, and multiple testing ideas | Chapter 13 covers linear and logistic regression | Chapters 7-8 review empirical distributions and bootstrap | Chapter 16 covers causal inference | . | Computer-Age Statistical Inference This book takes a fairly modern view of statistics, often examining the influence of computation on the field. It is useful to keep in mind that the book was written with masters’ students in mind. As such, this textbook covers many topics beyond the scope of this course, but nevertheless provides useful, high-level discussion of some course topics for those students looking for additional information. For example: . | Chapters 2 and 3 do an excellent job of comparing and contrasting frequentist and Bayesian inference, with illustrative examples | Chapter 4 discusses maximum likelihood estimation | Chapter 15 provides additional details about multiple hypothesis testing and false discovery rate control | There is also one section each on logistic regression, the EM algorithm, the bootstrap, conjugate priors, and Gibbs sampling | . | Causal Inference: The Mixtape This book is a great introduction and reference for all things causal inference. | Introduction to Statistical Learning (Free online PDF) This book is a great reference for the machine learning and some of the statistics material in the class . | Data Science from Scratch (Available as eBook for Berkeley students) This more applied book covers many of the topics in this class using Python but doesn’t go into sufficient depth for some of the more mathematical material. | Doing Data Science (Available as eBook for Berkeley students) This books provides a unique case-study view of data science but uses R and not Python. | Matrix Cookbook This “cookbook” is a handy collection of facts about linear algebra and matrices. | . ",
    "url": "/fa23/resources/#reading-resources",
    
    "relUrl": "/resources/#reading-resources"
  },"91": {
    "doc": "Staff",
    "title": "Staff",
    "content": "Jump to: Instructors, Teaching Assistants, Tutors. Note: Consult the calendar for the most up-to-date office hours for each GSI. ",
    "url": "/fa23/staff/",
    
    "relUrl": "/staff/"
  },"92": {
    "doc": "Staff",
    "title": "Course Staff Email",
    "content": "Contact course staff via Ed with any questions or concerns. For sensitive matters, the staff email address data102@berkeley.edu is monitored by the instructors and a few lead TAs. ",
    "url": "/fa23/staff/#course-staff-email",
    
    "relUrl": "/staff/#course-staff-email"
  },"93": {
    "doc": "Staff",
    "title": "Instructors",
    "content": "Aditya Guntuboyina . aditya@stat.berkeley.edu . Ramesh Sridharan . ramesh_s@berkeley.edu . ",
    "url": "/fa23/staff/#instructors",
    
    "relUrl": "/staff/#instructors"
  },"94": {
    "doc": "Staff",
    "title": "Teaching Assistants",
    "content": "Alan Jian He/Him/His . alanjian131@berkeley.edu . Hi there, my name is Alan and I’m a 5th year MIDS student. When I’m not doing data things, I’m likely playing tennis, going on a run, or reading a book! . Dominic Liu He/Him/His . hangxingliu@berkeley.edu . Hi! I’m a master student in Statistics. Hope you’ll enjoy this class as much as I did. Jonathan Meshkanian He/Him/His . jmeshkanian@berkeley.edu . Hi, I’m a senior CS and Applied Math major, I love sports, especially basketball, music, video games, and poker. Feel free to reach out to me about anything! . Mariel Werner She/Her/Hers . mariel_werner@berkeley.edu . Hey I’m Mariel, PhD student studying theory of machine learning. I’m from Montana, love playing music, running, and want to start a company! . Nathan Harounian He/Him/His . nathanharounian@berkeley.edu . Hey! I’m a senior studying Statistics and Data Science. In my free time, I enjoy hanging out with my friends, listening to music, archery, and poker! I really enjoyed taking Data 102 last spring and look forward to helping y’all this fall :) . ",
    "url": "/fa23/staff/#teaching-assistants",
    
    "relUrl": "/staff/#teaching-assistants"
  },"95": {
    "doc": "Staff",
    "title": "Tutors",
    "content": "Evelyn Li She/Her/Hers . eve2018@berkeley.edu . Hi, let’s explore data 102 and food together! . Lulu Dai She/Her/Hers . luludai@berkeley.edu . Hey everyone! I’m a senior from SLO, CA studying Data Science &amp; Public Health. I love eating/cooking, crocheting, and cats! . Yehchan Yoo He/Him/His . yehchanyoo@berkeley.edu . Hello — I am a senior majoring in Statistics and Political Economy &amp; minoring in Data Science; I like to read the news, watch YouTube videos, listen to rock and electronic music, meditate, lift weights, and do boxing in my free time. Hope you all will enjoy the course, and always feel free to reach out! . ",
    "url": "/fa23/staff/#tutors",
    
    "relUrl": "/staff/#tutors"
  },"96": {
    "doc": "Syllabus",
    "title": "Syllabus",
    "content": "Jump to: . | About the Course | Prerequisites | Course Components | Grading Policies . | Grading Scheme | Regrade requests | Slip Days | Extenuating Circumstances | DSP Accommodations | Collaboration and Academic Integrity | . | Waitlist | Community Resources | . ",
    "url": "/fa23/syllabus/",
    
    "relUrl": "/syllabus/"
  },"97": {
    "doc": "Syllabus",
    "title": "About the Course",
    "content": "This course develops the probabilistic foundations of inference in data science. It builds a comprehensive view of the decision-making and modeling life cycle in data science, including its human, social, and ethical implications. Topics include: frequentist and Bayesian decision-making, permutation testing, false discovery rate, probabilistic interpretations of models, Bayesian hierarchical models, basics of experimental design, confidence intervals, causal inference, robustness, Thompson sampling, optimal control, Q-learning, differential privacy, fairness in classification, recommendation systems and an introduction to machine learning tools including decision trees, neural networks and ensemble methods. This class is listed as Data 102. ",
    "url": "/fa23/syllabus/#about-the-course",
    
    "relUrl": "/syllabus/#about-the-course"
  },"98": {
    "doc": "Syllabus",
    "title": "Prerequisites",
    "content": "While we are working to make this class widely accessible, we currently require the following (or equivalent) prerequisites : . | Principles and Techniques of Data Science: Data 100 covers important computational and statistical skills that will be necessary for Data 102. | Probability: Data 140, EECS 126, STAT 134, IEOR 172, or Math 106. Data 140 and EECS 126 are preferred. These courses cover the probabilistic tools that will form the underpinning for the concepts covered in Data 102. | Math: Math 54, Math 56, Math 110, both EE 16A and EE 16B, STAT 89a, or Physics 89. We will need some basic concepts like linear operators, eigenvectors, derivatives, and integrals to enable statistical inference and derive new prediction algorithms. | . Please consult the Resources page for additional resources for reviewing prerequisite material. ",
    "url": "/fa23/syllabus/#prerequisites",
    
    "relUrl": "/syllabus/#prerequisites"
  },"99": {
    "doc": "Syllabus",
    "title": "Course Components",
    "content": "Lectures . Lectures will be held in-person Tuesdays and Thursdays from 3:30 - 5pm in Li Ka Shing 245. Recordings will be made available on the course website within 24 hours. Discussion sessions . Discussion section will be held on Wednesdays, led by your GSIs. These sections will cover important problem-solving skills that bridge the concepts in lectures with the skills you’ll need to apply the ideas on the homework and beyond. A few weeks into the semester, we will start the Supplemental Sections. A typical Supplemental Section consists of prerequisite content you might’ve forgotten or missed from Data 100/140 and “catch up” content to reinforce material you may have missed in the previous week. Details will be posted on Ed. Attending these sections is optional. Lab sessions . Labs will be held on Mondays by GSIs. You will be working on lab assignments with your GSI in these sections. You can complete the assignments on your own time, but you are highly encouraged to attend lab sessions to work with your classmates and get help from the staff. Help will be limited on Ed and office hours because of this. Homeworks . Homework assignments are released every other week on Fridays and due two Fridays after. These assignments are designed to help students develop an in-depth understanding of both the theoretical and practical aspects of ideas presented in lectures. They contain both math and coding tasks. | All homeworks must be submitted to Gradescope by their posted deadlines. | Each assignment will include detailed instructions on how to submit your work for grading. It is the student’s responsibility to read these carefully and ensure that their work is submitted correctly. Assignment accommodations will not be granted in cases where students have mis-submitted their work (for example, by submitting to the wrong portal, submitting only part of an assignment, or forgetting to select pages). | The primary form of support students will have for homeworks are office hours and Ed. | . Vitamins . Vitamins are weekly short Gradescope assignments to check that you are keeping up with lectures. They will be released on Thursdays after lecture and due on Sundays. Exams . There will be two midterms in this class: . | Midterm 1 on October 5, 2023, 7-9PM | Midterm 2 on November 14, 2023, 7-9PM | . There will not be a final exam. All exams must be taken in-person. You must sit the midterms at the specified time: if you have a conflict, please contact course staff ASAP at data102@berkeley.edu. We will not accept any conflicts after the drop deadline. Final Project . At the end of the semester, you will apply the knowledge you learned in this class on a real-world dataset to complete a final project. You will be working in groups of 4. More details will be announced on Ed closer to the end of term. ",
    "url": "/fa23/syllabus/#course-components",
    
    "relUrl": "/syllabus/#course-components"
  },"100": {
    "doc": "Syllabus",
    "title": "Grading Policies",
    "content": "Grading Scheme . Grades will be assigned using the following weighted components: . | Category | Percentage | Details | . | Vitamins | 5% | Drop 2 lowest scores | . | Homeworks | 20% | No drop; 5 slip days | . | Labs | 15% | Drop 2 lowest scores | . | Midterm 1 | 20% |   | . | Midterm 2 | 20% |   | . | Final project | 20% |   | . Grading criteria . | Homework will be graded on completion and correctness. No assignment may be dropped, but we have a slip day policy (see below). | Lab assignments will be graded on completion and correctness, but all test cases for autograded questions will be public. Your two lowest lab scores will be dropped. | When submitting assignments on Gradescope, you must match each page to the corresponding question on Gradescope. If you fail to do so, you may not receive credit for your work! | A grading rubric and more details regarding the final project will be released later in the semester. | . Regrade requests . | After each assignment is graded, course staff will post the deadline for regrade requests for that assignment on Ed. | To ensure that our grading team is not overworked, regrade requests for each assignment must be submitted before the deadline (except in cases of emergencies). | Note: When you submit a regrade request, we will take a fresh look at the question, so it is possible that you will receive a grade lower that what you originally received. | . Slip Days . Each student gets an extension budget of 5 total slip days. You can use the extension on homework assignments only (not lab assignments, vitamins, or the final project) during the semester. Some important notes on slip days: . | Do not plan to use your slip days: we’re providing them for unforeseen circumstances. | Slip days are self-serve: we’ll apply them to your assignments automatically. | Slip days are full days, not hours. We round up, so if you are 1 hour late, then 1 slip day will be used. (Why? We’d rather you get some sleep and make an attempt to finish the assignment the next day instead of staying up to micromanage hours.) | After you have used your slip-time budget, any assignment handed in late will be marked off 20% per day late (rounded up to the nearest integer number of days). | No assignment will be accepted more than 5 days late. | . Extenuating Circumstances . We recognize that our students come from varied backgrounds and have widely-varying experiences. If you encounter extenuating circumstances at any time in the semester, please do not hesitate to let us know. The sooner we are made aware, the more options we have available to us to help you. The Extenuating Circumstances Form is for any circumstances that cannot be resolved via slip days and drops. Within two business days of filling out the form, a course staff will reach out to you and provide a space for conversation, as well as to arrange course/grading accommodations as necessary. For more information, please email data102@berkeley.edu. We recognize that at times, it can be difficult to manage your course performance — particularly in such a huge course, and particularly at Berkeley’s high standards. Sometimes emergencies just come up (personal health emergency, family emergency, etc.). The Extenuating Circumstances Form is meant to lower the barrier to reaching out to us, as well as build your independence in managing your academic career long-term. So please do not hesitate to reach out. Note that extenuating circumstances do not extend to the following: . | Logistical oversight, such as Datahub/Gradescope tests not passing, submitting only one portion of the homework, forgetting to save your notebook before exporting, submitting to the wrong assignment portal, or not properly tagging pages on Gradescope. It is the student’s responsibility to identify and resolve these issues in advance of the deadlines. | Workload-related issues. It is the student’s responsibility to manage their other coursework and extracurricular commitments. We will not grant accommodations for these cases; instead, please use drops or slip days to cushion these issues. | Requests made after the assignment deadlines. Please make sure to submit a request before the assignment is due. | . Finally, simply submitting a request does not guarantee you will receive an extension. Even if your work is incomplete, please submit before the deadline so you can receive credit for the work you did complete. DSP Accommodations . If you are registered with the Disabled Students’ Program (DSP) you can expect to receive an email from us during the first week of classes confirming your accommodations. Otherwise, email data102@berkeley.edu. DSP students who receive approved assignment accommodations will have a 2-day extension on homeworks and 1-day extension on labs and vitamins. Please note that any extension, plus slip days, cannot exceed 5 days. DSP students can submit assignment extension accommodation requests via the Extenuating Circumstances Form. You are responsible for reasonable communication with course staff. If you make a request close to the deadline, we can not guarantee that you will receive a response before the deadline. Collaboration and Academic Integrity . Data science is a collaborative activity. While you may talk with others about the homework, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names at the top of your notebook. Keep in mind that content from the homeworks and labs will likely be covered on both of the midterms. We will be following the campus policy on Academic Honesty, so be sure you are familiar with it. As a member of the Berkeley community, we expect you to follow the Berkeley Honor Code: . “As a member of the UC Berkeley community, I act with honesty, integrity, and respect for others.” . ",
    "url": "/fa23/syllabus/#grading-policies",
    
    "relUrl": "/syllabus/#grading-policies"
  },"101": {
    "doc": "Syllabus",
    "title": "Waitlist",
    "content": "If you are on the waitlist, you should complete and submit all assignments as if enrolled: we will not offer any makeup assignments or extensions for waitlisted students. For all other enrollment related issues, please reach out to the Data Science advisors, as instructors and staff do not manage enrollment into the class. ",
    "url": "/fa23/syllabus/#waitlist",
    
    "relUrl": "/syllabus/#waitlist"
  },"102": {
    "doc": "Syllabus",
    "title": "Community Resources",
    "content": "Device Lending options . Students can access device lending options through the Student Technology Equity Program STEP program. Data Science Student Climate . Data Science Undergraduate Studies faculty and staff are committed to creating a community where every person feels respected, included, and supported. We recognize that incidents may happen, sometimes unintentionally, that run counter to this goal. There are many things we can do to try to improve the climate for students, but we need to understand where the challenges lie. If you experience a remark, or disrespectful treatment, or if you feel you are being ignored, excluded or marginalized in a course or program-related activity, please speak up. Consider talking to your instructor, but you are also welcome to contact Executive Director Christina Teller at cpteller@berkeley.edu or report an incident anonymously through this online form. Community Standards . Ed is a formal, academic space. We must demonstrate appropriate respect, consideration, and compassion for others. Please be friendly and thoughtful; our community draws from a wide spectrum of valuable experiences. For further reading, please reference Berkeley’s Principles of Community and the Berkeley Campus Code of Student Conduct. ",
    "url": "/fa23/syllabus/#community-resources",
    
    "relUrl": "/syllabus/#community-resources"
  }
}
